{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Install dependencies\n",
    "!pip install torch==2.1.0 diffusers==0.23.0 transformers>=4.35.0 gradio --quiet"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from diffusers import QwenImageEditPipeline\n",
    "\n",
    "# Optional simple prompt cleaner\n",
    "def simple_clean(prompt: str):\n",
    "    return prompt.strip()\n",
    "\n",
    "dtype = torch.bfloat16\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "pipe = QwenImageEditPipeline.from_pretrained(\n",
    "    'Qwen/Qwen-Image-Edit',\n",
    "    torch_dtype=dtype\n",
    ").to(device)\n",
    "\n",
    "MAX_SEED = np.iinfo(np.int32).max\n",
    "\n",
    "def infer(\n",
    "    image,\n",
    "    prompt,\n",
    "    seed=42,\n",
    "    randomize_seed=False,\n",
    "    true_guidance_scale=4.0,\n",
    "    num_inference_steps=30,\n",
    "    rewrite_prompt=True\n",
    "):\n",
    "    if randomize_seed:\n",
    "        seed = random.randint(0, MAX_SEED)\n",
    "    generator = torch.Generator(device=device).manual_seed(seed)\n",
    "\n",
    "    if rewrite_prompt:\n",
    "        prompt = simple_clean(prompt)\n",
    "\n",
    "    negative_prompt = ' '\n",
    "\n",
    "    images = pipe(\n",
    "        image,\n",
    "        prompt=prompt,\n",
    "        negative_prompt=negative_prompt,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        generator=generator,\n",
    "        true_cfg_scale=true_guidance_scale,\n",
    "        num_images_per_prompt=1\n",
    "    ).images\n",
    "\n",
    "    return images[0], seed\n",
    "\n",
    "def run_edit(img, pr, sd):\n",
    "    return infer(img, pr, sd)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "with gr.Blocks(title='Offline Qwen Image Edit') as demo:\n",
    "    with gr.Row():\n",
    "        input_image = gr.Image(type='pil', label='Input Image')\n",
    "        result_image = gr.Image(type='pil', label='Edited Result')\n",
    "\n",
    "    prompt_box = gr.Textbox(label='Prompt / Edit Instruction', placeholder='Describe the image edit')\n",
    "    seed_slider = gr.Slider(0, MAX_SEED, value=42, label='Seed')\n",
    "    run_btn = gr.Button('Edit Image')\n",
    "\n",
    "    run_btn.click(\n",
    "        fn=lambda i, p, s: run_edit(i, p, s),\n",
    "        inputs=[input_image, prompt_box, seed_slider],\n",
    "        outputs=[result_image, seed_slider]\n",
    "    )\n",
    "\n",
    "demo"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Launch the app\n",
    "demo.launch(share=True)"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Qwen_Image_Edit_Offline",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 14
}
